{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM and other simple classifiers for scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.path.abspath(\"./aml/src/prep/utils.py\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file with preprocessed reviews into a DataFrame\n",
    "path = '../data/processed_reviews.csv'\n",
    "proc_reviews = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Time</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Usefulness</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>useless</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>useless</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId        Time SentimentPolarity  Class_Labels  \\\n",
       "0  B001E4KFG0  A3SGXH7AUHU8GW  2011-04-27          Positive             1   \n",
       "1  B00813GRG4  A1D87F6ZCVE5NK  2012-09-07          Negative             0   \n",
       "2  B000LQOCH0   ABXLMWJIXXAIN  2008-08-18          Positive             1   \n",
       "3  B000UA0QIQ  A395BORC6FGVXV  2011-06-13          Negative             0   \n",
       "4  B006K2ZZ7K  A1UQRSCLF8GW1T  2012-10-21          Positive             1   \n",
       "\n",
       "  Sentiment Usefulness                                        CleanedText  \\\n",
       "0  positive       >75%  bought sever vital can dog food product found ...   \n",
       "1  negative    useless  product arriv label jumbo salt peanut peanut a...   \n",
       "2  positive       >75%  confect around centuri light pillowi citrus ge...   \n",
       "3  negative       >75%  look secret ingredi robitussin believ found go...   \n",
       "4  positive    useless  great taffi great price wide assort yummi taff...   \n",
       "\n",
       "   Score  \n",
       "0      5  \n",
       "1      1  \n",
       "2      4  \n",
       "3      2  \n",
       "4      5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 393890 entries, 0 to 393889\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   ProductId          393890 non-null  object\n",
      " 1   UserId             393890 non-null  object\n",
      " 2   Time               393890 non-null  object\n",
      " 3   SentimentPolarity  393890 non-null  object\n",
      " 4   Class_Labels       393890 non-null  int64 \n",
      " 5   Sentiment          393890 non-null  object\n",
      " 6   Usefulness         393890 non-null  object\n",
      " 7   CleanedText        393884 non-null  object\n",
      " 8   Score              393890 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 27.0+ MB\n"
     ]
    }
   ],
   "source": [
    "proc_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_reviews = proc_reviews[proc_reviews['CleanedText'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Time</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Usefulness</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>useless</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>useless</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId        Time SentimentPolarity  Class_Labels  \\\n",
       "0  B001E4KFG0  A3SGXH7AUHU8GW  2011-04-27          Positive             1   \n",
       "1  B00813GRG4  A1D87F6ZCVE5NK  2012-09-07          Negative             0   \n",
       "2  B000LQOCH0   ABXLMWJIXXAIN  2008-08-18          Positive             1   \n",
       "3  B000UA0QIQ  A395BORC6FGVXV  2011-06-13          Negative             0   \n",
       "4  B006K2ZZ7K  A1UQRSCLF8GW1T  2012-10-21          Positive             1   \n",
       "\n",
       "  Sentiment Usefulness                                        CleanedText  \\\n",
       "0  positive       >75%  bought sever vital can dog food product found ...   \n",
       "1  negative    useless  product arriv label jumbo salt peanut peanut a...   \n",
       "2  positive       >75%  confect around centuri light pillowi citrus ge...   \n",
       "3  negative       >75%  look secret ingredi robitussin believ found go...   \n",
       "4  positive    useless  great taffi great price wide assort yummi taff...   \n",
       "\n",
       "   Score  \n",
       "0      5  \n",
       "1      1  \n",
       "2      4  \n",
       "3      2  \n",
       "4      5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - validation - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val_test, Y_train, Y_val_test = train_test_split(\n",
    "    proc_reviews[['CleanedText','Class_Labels']], proc_reviews['Class_Labels'], test_size=0.3, random_state=42, stratify=proc_reviews['Class_Labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val, data_test, Y_val, Y_test = train_test_split(\n",
    "    data_val_test['CleanedText'], Y_val_test, test_size=0.333, random_state=42, stratify=data_val_test['Class_Labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate text from score on X_train (score was just kept for the second splitting)\n",
    "data_train = data_train['CleanedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275718,) (275718,)\n",
      "(78816,) (78816,)\n",
      "(39350,) (39350,)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape,Y_train.shape)\n",
    "print(data_val.shape,Y_val.shape)\n",
    "print(data_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 250928, 4: 56086, 1: 36301, 3: 29768, 2: 20801})\n",
      "Counter({1: 214909, 0: 60809})\n",
      "Counter({1: 61433, 0: 17383})\n",
      "Counter({1: 30672, 0: 8678})\n",
      "overall fractions = 63.71% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n",
      "train fractions = 0.00% 5 - 0.00% 4 - 0.00% 3 - 0.00% 2 - 77.95% 1\n",
      "val fractions = 0.00% 5 - 0.00% 4 - 0.00% 3 - 0.00% 2 - 77.94% 1\n",
      "test fractions = 0.00% 5 - 0.00% 4 - 0.00% 3 - 0.00% 2 - 77.95% 1\n"
     ]
    }
   ],
   "source": [
    "# Double check stratification is ok over the three splits\n",
    "\n",
    "all_counter = Counter(list(proc_reviews['Score']))\n",
    "train_counter = Counter(list(Y_train))\n",
    "val_counter = Counter(list(Y_val))\n",
    "test_counter = Counter(list(Y_test))\n",
    "\n",
    "num_all = len(list(proc_reviews['Score']))\n",
    "num_train = len(list(Y_train))\n",
    "num_val = len(list(Y_val))\n",
    "num_test = len(list(Y_test))\n",
    "\n",
    "print(all_counter)\n",
    "print(train_counter)\n",
    "print(val_counter)\n",
    "print(test_counter)\n",
    "\n",
    "print(f\"overall fractions = {all_counter[5]/num_all*100:.2f}% 5 - {all_counter[4]/num_all*100:.2f}% 4 - {all_counter[3]/num_all*100:.2f}% 3 - {all_counter[2]/num_all*100:.2f}% 2 - {all_counter[1]/num_all*100:.2f}% 1\")\n",
    "print(f\"train fractions = {train_counter[5]/num_train*100:.2f}% 5 - {train_counter[4]/num_train*100:.2f}% 4 - {train_counter[3]/num_train*100:.2f}% 3 - {train_counter[2]/num_train*100:.2f}% 2 - {train_counter[1]/num_train*100:.2f}% 1\")\n",
    "print(f\"val fractions = {val_counter[5]/num_val*100:.2f}% 5 - {val_counter[4]/num_val*100:.2f}% 4 - {val_counter[3]/num_val*100:.2f}% 3 - {val_counter[2]/num_val*100:.2f}% 2 - {val_counter[1]/num_val*100:.2f}% 1\")\n",
    "print(f\"test fractions = {test_counter[5]/num_test*100:.2f}% 5 - {test_counter[4]/num_test*100:.2f}% 4 - {test_counter[3]/num_test*100:.2f}% 3 - {test_counter[2]/num_test*100:.2f}% 2 - {test_counter[1]/num_test*100:.2f}% 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization strategy\n",
    "\n",
    "* TfidfVectorizer/CountVectorizer\n",
    "* FastVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorizer model\n",
    "# Use parameters in filename to identify what was used\n",
    "\n",
    "def get_fname(vect_type, params_dic):\n",
    "\n",
    "    fname = \"\"\n",
    "\n",
    "    for k,v in params_dic.items():\n",
    "        \n",
    "        fname += k + \"_\" + str(v) + \"_\"\n",
    "\n",
    "    fname = fname.replace(\"(\", \"_\")\n",
    "    fname = fname.replace(\")\", \"_\")\n",
    "    fname = fname.replace(\",\", \"_\")\n",
    "    fname = fname.replace(\" \", \"\")\n",
    "    fname = fname.replace(\"__\", \"_\")\n",
    "\n",
    "    fname = vect_type + '_' + fname[:-1]\n",
    "\n",
    "    return fname\n",
    "\n",
    "def save_vectorizer(data_path, _vectorizer, vect_type, params_dic):\n",
    "\n",
    "    vect_fname = get_fname(vect_type, params_dic)+'.pkl'\n",
    "\n",
    "    os.makedirs(data_path+'vectorizers/',exist_ok=True)\n",
    "\n",
    "    with open(data_path+'vectorizers/'+ vect_fname, 'wb') as f:\n",
    "        pickle.dump(_vectorizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vect = utils.doc_vectorizer(data_train, data_val, data_test,\n",
    "\"tfidf\", {'min_df':1, 'ngram_range':(1,3)})\n",
    "\n",
    "#X_train_tfidf, X_val_tfidf, X_test_tfidf = utils.doc_vectorizer(data_train, data_val, data_test,\n",
    "#\"tfidf\", {'min_df':1, 'ngram_range':(1,4), 'max_features':100000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275718, 10145002)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorizer\n",
    "data_path = '../data/bin_model/'\n",
    "save_vectorizer(data_path, tfidf_vect, \"tfidf_vect\", {'min_df':1, 'ngram_range':(1,3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_doc2vec, X_val_doc2vec, X_test_doc2vec, doc2vec_model = utils.doc_vectorizer(data_train, data_val, data_test, \"doc2vec\",\n",
    "                                                                      {'vector_size':2000, 'window':3, 'min_count':4, 'workers':2, 'epochs':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cntVec, X_val_cntVec, X_test_cntVec, countVec = utils.doc_vectorizer(data_train, data_val, data_test, \"countVec\",\n",
    "                                                                      {'min_df':1, 'ngram_range':(1,3)})\n",
    "\n",
    "#X_train_cntVec, X_val_cntVec, X_test_cntVec = utils.doc_vectorizer(data_train, data_val, data_test, \"countVec\",\n",
    "#                                                                      {'stop_words': None, 'min_df':1, 'max_df':1,\n",
    "#                                                                       'ngram_range':(1,3), 'max_features': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many features we are left with \n",
    "print(X_train_tfidf.shape)\n",
    "#print(X_train_doc2vec.shape)\n",
    "#print(X_train_cntVec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models analysis and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models to try\n",
    "from sklearn.svm import LinearSVC # Support vector machine\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svm(random_state=42, tol=1e-3, class_weight='balanced'):\n",
    "\n",
    "    return LinearSVC(random_state=random_state, tol=tol, class_weight=class_weight)\n",
    "\n",
    "def train_svm(_model, X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "\n",
    "    _model.fit(X_train,Y_train)\n",
    "\n",
    "    Y_train_pred = _model.predict(X_train)\n",
    "\n",
    "    train_acc = accuracy_score(Y_train,Y_train_pred)\n",
    "\n",
    "    Y_val_pred = _model.predict(X_val)\n",
    "\n",
    "    val_acc = accuracy_score(Y_val,Y_val_pred)\n",
    "\n",
    "    Y_test_pred = _model.predict(X_test)\n",
    "\n",
    "    test_acc = accuracy_score(Y_test,Y_test_pred)\n",
    "\n",
    "    print(f\"train_acc: {train_acc}\")\n",
    "    print(f\"val_acc: {val_acc}\")\n",
    "    print(f\"test_acc: {test_acc}\")\n",
    "\n",
    "    return _model, val_acc, test_acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and metrics\n",
    "def save_model_metrics(data_path, _model, model_type, model_params, X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "\n",
    "    report_name = get_fname(model_type, model_params)\n",
    "\n",
    "    Y_train_pred = _model.predict(X_train)\n",
    "\n",
    "    Y_val_pred = _model.predict(X_val)\n",
    "\n",
    "    Y_test_pred = _model.predict(X_test)\n",
    "\n",
    "\n",
    "    train_acc = accuracy_score(Y_train,Y_train_pred)\n",
    "\n",
    "    val_acc = accuracy_score(Y_val,Y_val_pred)\n",
    "\n",
    "    test_acc = accuracy_score(Y_test,Y_test_pred)\n",
    "\n",
    "    report_train = classification_report(Y_train,Y_train_pred, output_dict=True)\n",
    "\n",
    "    report_val = classification_report(Y_val,Y_val_pred, output_dict=True)\n",
    "\n",
    "    report_test = classification_report(Y_test,Y_test_pred, output_dict=True)\n",
    "\n",
    "    #df_val = pd.DataFrame(report_val)#.transpose()\n",
    "\n",
    "    #df_test = pd.DataFrame(report_test)#.transpose()\n",
    "\n",
    "    reports_path = data_path + report_name + \"/\"\n",
    "\n",
    "    os.makedirs(reports_path,exist_ok=True)\n",
    "\n",
    "    report_path_train = reports_path + 'report_val_' + report_name + '.pkl'\n",
    "    report_path_val = reports_path + 'report_val_' + report_name + '.pkl'\n",
    "    report_path_test = reports_path + 'report_test_' + report_name + '.pkl'\n",
    "\n",
    "    with open(report_path_train, 'wb') as f:\n",
    "        pickle.dump(report_train, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(report_path_val, 'wb') as f:\n",
    "        pickle.dump(report_val, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(report_path_test, 'wb') as f:\n",
    "        pickle.dump(report_test, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    #df_val = pd.DataFrame.from_dict(report_val)\n",
    "    #df_val.to_csv(report_path_val, index = False)\n",
    "\n",
    "    #df_test = pd.DataFrame.from_dict(report_val)\n",
    "    #df_test.to_csv(report_path_test, index = False)\n",
    "\n",
    "    print(\"Train dset metrics:\")\n",
    "    print(classification_report(Y_train,Y_train_pred))    \n",
    "    print()\n",
    "    print(\"Validation dset metrics:\")\n",
    "    print(classification_report(Y_val,Y_val_pred))    \n",
    "    print()\n",
    "    print(\"Test dset metrics:\")\n",
    "    print(classification_report(Y_test,Y_test_pred))    \n",
    "    print()\n",
    "\n",
    "    confusion_m = confusion_matrix(Y_test, Y_test_pred)\n",
    "\n",
    "    print(\"Test confusion matrix\")\n",
    "    print(confusion_m)\n",
    "\n",
    "    with open(reports_path + 'confusion_matrix_test.pkl', 'wb') as f:\n",
    "        pickle.dump(confusion_m, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j.martins\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.9988067518261412\n",
      "val_acc: 0.9066179455948031\n",
      "test_acc: 0.9049809402795426\n"
     ]
    }
   ],
   "source": [
    "tfidf_params = {\"random_state\":42, \"tol\":1e-4, \"class_weight\":'balanced'}\n",
    "\n",
    "model_tfidf = build_svm(**tfidf_params)\n",
    "\n",
    "model_tfidf, val_acc, test_acc = train_svm(model_tfidf, X_train_tfidf, Y_train, X_val_tfidf, Y_val, X_test_tfidf, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_model_metrics() missing 2 required positional arguments: 'X_test' and 'Y_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/bin_model/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43msave_model_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_tfidf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidf_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: save_model_metrics() missing 2 required positional arguments: 'X_test' and 'Y_test'"
     ]
    }
   ],
   "source": [
    "data_path = '../data/bin_model/'\n",
    "\n",
    "save_model_metrics(data_path, model_tfidf, \"model_tfidf\", tfidf_params, X_train_tfidf, Y_train, X_val_tfidf, Y_val, X_test_tfidf, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cntVec = build_svm(random_state=42, tol=1e-3, class_weight='balanced')\n",
    "\n",
    "model_cntVec, val_acc_2, test_acc_2 = train_svm(model_cntVec, X_train_cntVec, Y_train, X_val_cntVec, Y_val, X_test_cntVec, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_2, test_acc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc2vec = build_svm(random_state=42, tol=1e-3, class_weight='balanced')\n",
    "\n",
    "model_doc2vec, val_acc_3, test_acc_3 = train_svm(model_doc2vec, X_train_doc2vec, Y_train, X_val_doc2vec, Y_val, X_test_doc2vec, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_3, test_acc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=10, max_depth=3, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = gb_model.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = gb.predict(X_val_tfidf)\n",
    "\n",
    "Y_test_pred = gb.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "val_acc = accuracy_score(Y_val,Y_val_pred)\n",
    "\n",
    "test_acc = accuracy_score(Y_test,Y_test_pred)\n",
    "\n",
    "print(val_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = rf_model.fit(X_train_tfidf, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
