{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBoost scoring classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file with preprocessed reviews into a DataFrame\n",
    "path = './review-analysis-teamc/data/processed_reviews.csv'\n",
    "proc_reviews = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>helpfulness_numerator</th>\n",
       "      <th>helpfulness_denominator</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>helpfulness_ratio</th>\n",
       "      <th>word_count</th>\n",
       "      <th>duplicated</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>2011</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>2012</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>product arrived labeled jumbo salted peanuts ....</td>\n",
       "      <td>product arrived labeled jumbo salted peanut .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>2008</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>2012</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>2012</td>\n",
       "      <td>positive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "      <td>got wild hair taffy ordered five pound bag taf...</td>\n",
       "      <td>got wild hair taffy ordered five pound bag taf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  product_id         user_id  helpfulness_numerator  \\\n",
       "0           0   1  B001E4KFG0  A3SGXH7AUHU8GW                      1   \n",
       "1           1   2  B00813GRG4  A1D87F6ZCVE5NK                      0   \n",
       "2           2   3  B000LQOCH0   ABXLMWJIXXAIN                      1   \n",
       "3           4   5  B006K2ZZ7K  A1UQRSCLF8GW1T                      0   \n",
       "4           5   6  B006K2ZZ7K   ADT0SRK1MGOEU                      0   \n",
       "\n",
       "   helpfulness_denominator  score        time                summary  \\\n",
       "0                        1      5  1303862400  Good Quality Dog Food   \n",
       "1                        0      1  1346976000      Not as Advertised   \n",
       "2                        1      4  1219017600  \"Delight\" says it all   \n",
       "3                        0      5  1350777600            Great taffy   \n",
       "4                        0      4  1342051200             Nice Taffy   \n",
       "\n",
       "                                                text        date  year  \\\n",
       "0  I have bought several of the Vitality canned d...  2011-04-27  2011   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  2012-09-07  2012   \n",
       "2  This is a confection that has been around a fe...  2008-08-18  2008   \n",
       "3  Great taffy at a great price.  There was a wid...  2012-10-21  2012   \n",
       "4  I got a wild hair for taffy and ordered this f...  2012-07-12  2012   \n",
       "\n",
       "  sentiment  helpfulness_ratio  word_count  duplicated  \\\n",
       "0  positive                1.0          48       False   \n",
       "1  negative                NaN          31       False   \n",
       "2  positive                1.0          94       False   \n",
       "3  positive                NaN          27       False   \n",
       "4  positive                NaN          72       False   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  bought several vitality canned dog food produc...   \n",
       "1  product arrived labeled jumbo salted peanuts ....   \n",
       "2  confection around centuries light pillowy citr...   \n",
       "3  great taffy great price wide assortment yummy ...   \n",
       "4  got wild hair taffy ordered five pound bag taf...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  bought several vitality canned dog food produc...  \n",
       "1  product arrived labeled jumbo salted peanut .....  \n",
       "2  confection around century light pillowy citrus...  \n",
       "3  great taffy great price wide assortment yummy ...  \n",
       "4  got wild hair taffy ordered five pound bag taf...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - validation - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val_test, Y_train, Y_val_test = train_test_split(\n",
    "    proc_reviews[['lemmatized_text','score']], proc_reviews['score'], test_size=0.2, random_state=42, stratify=proc_reviews['score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val, data_test, Y_val, Y_test = train_test_split(\n",
    "    data_val_test['lemmatized_text'], Y_val_test, test_size=0.333, random_state=42, stratify=data_val_test['score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate lemmatized text from score on X_train (score was just kept for the second splitting)\n",
    "data_train = data_train['lemmatized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n",
      "(315091,) (315091,)\n",
      "(52541,) (52541,)\n",
      "(26232,) (26232,)\n"
     ]
    }
   ],
   "source": [
    "print(type(data_train),type(data_val),type(data_test))\n",
    "print(type(Y_train),type(Y_val),type(Y_test))\n",
    "\n",
    "print(data_train.shape,Y_train.shape)\n",
    "print(data_val.shape,Y_val.shape)\n",
    "print(data_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 250902, 4: 56089, 1: 36299, 3: 29771, 2: 20803})\n",
      "Counter({5: 200722, 4: 44871, 1: 29039, 3: 23817, 2: 16642})\n",
      "Counter({5: 33470, 4: 7482, 1: 4843, 3: 3971, 2: 2775})\n",
      "Counter({5: 16710, 4: 3736, 1: 2417, 3: 1983, 2: 1386})\n",
      "overall fractions = 63.70% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n",
      "train fractions = 63.70% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n",
      "val fractions = 63.70% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n",
      "test fractions = 63.70% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.21% 1\n"
     ]
    }
   ],
   "source": [
    "# Double check stratification is ok over the three splits\n",
    "\n",
    "all_counter = Counter(list(proc_reviews['score']))\n",
    "train_counter = Counter(list(Y_train))\n",
    "val_counter = Counter(list(Y_val))\n",
    "test_counter = Counter(list(Y_test))\n",
    "\n",
    "num_all = len(list(proc_reviews['score']))\n",
    "num_train = len(list(Y_train))\n",
    "num_val = len(list(Y_val))\n",
    "num_test = len(list(Y_test))\n",
    "\n",
    "print(all_counter)\n",
    "print(train_counter)\n",
    "print(val_counter)\n",
    "print(test_counter)\n",
    "\n",
    "print(f\"overall fractions = {all_counter[5]/num_all*100:.2f}% 5 - {all_counter[4]/num_all*100:.2f}% 4 - {all_counter[3]/num_all*100:.2f}% 3 - {all_counter[2]/num_all*100:.2f}% 2 - {all_counter[1]/num_all*100:.2f}% 1\")\n",
    "print(f\"train fractions = {train_counter[5]/num_train*100:.2f}% 5 - {train_counter[4]/num_train*100:.2f}% 4 - {train_counter[3]/num_train*100:.2f}% 3 - {train_counter[2]/num_train*100:.2f}% 2 - {train_counter[1]/num_train*100:.2f}% 1\")\n",
    "print(f\"val fractions = {val_counter[5]/num_val*100:.2f}% 5 - {val_counter[4]/num_val*100:.2f}% 4 - {val_counter[3]/num_val*100:.2f}% 3 - {val_counter[2]/num_val*100:.2f}% 2 - {val_counter[1]/num_val*100:.2f}% 1\")\n",
    "print(f\"test fractions = {test_counter[5]/num_test*100:.2f}% 5 - {test_counter[4]/num_test*100:.2f}% 4 - {test_counter[3]/num_test*100:.2f}% 3 - {test_counter[2]/num_test*100:.2f}% 2 - {test_counter[1]/num_test*100:.2f}% 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization strategy\n",
    "\n",
    "* TfidfVectorizer\n",
    "* FastVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# X_train, X_val, X_test = utils.series2tfidf_vecs(data_train, data_val, data_test, min_df=1, ngram_range=(1,3))\n",
    "\n",
    "X_train, X_val, X_test = utils.doc_vectorizer(data_train, data_val, data_test, \"doc2vec\", {'vector_size':200, 'window':5, 'min_count':1, 'workers':4, 'epochs':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models analysis and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models to try\n",
    "import xgboost\n",
    "import sklearn \n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = GradientBoostingClassifier(\n",
    "    n_estimators=10, max_depth=3, random_state=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xgb_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = xgb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6370263223006795\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_val,Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
