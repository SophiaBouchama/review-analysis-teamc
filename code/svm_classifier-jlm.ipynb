{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM and other simple classifiers for scoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(os.path.abspath(\"./aml/src/prep/utils.py\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file with preprocessed reviews into a DataFrame\n",
    "path = '../data/processed_reviews.csv'\n",
    "proc_reviews = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Time</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Usefulness</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>useless</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>useless</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId        Time SentimentPolarity  Class_Labels  \\\n",
       "0  B001E4KFG0  A3SGXH7AUHU8GW  2011-04-27          Positive             1   \n",
       "1  B00813GRG4  A1D87F6ZCVE5NK  2012-09-07          Negative             0   \n",
       "2  B000LQOCH0   ABXLMWJIXXAIN  2008-08-18          Positive             1   \n",
       "3  B000UA0QIQ  A395BORC6FGVXV  2011-06-13          Negative             0   \n",
       "4  B006K2ZZ7K  A1UQRSCLF8GW1T  2012-10-21          Positive             1   \n",
       "\n",
       "  Sentiment  Score Usefulness  \\\n",
       "0  positive      5       >75%   \n",
       "1  negative      1    useless   \n",
       "2  positive      4       >75%   \n",
       "3  negative      2       >75%   \n",
       "4  positive      5    useless   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  bought sever vital can dog food product found ...  \n",
       "1  product arriv label jumbo salt peanut peanut a...  \n",
       "2  confect around centuri light pillowi citrus ge...  \n",
       "3  look secret ingredi robitussin believ found go...  \n",
       "4  great taffi great price wide assort yummi taff...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 393890 entries, 0 to 393889\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   ProductId          393890 non-null  object\n",
      " 1   UserId             393890 non-null  object\n",
      " 2   Time               393890 non-null  object\n",
      " 3   SentimentPolarity  393890 non-null  object\n",
      " 4   Class_Labels       393890 non-null  int64 \n",
      " 5   Sentiment          393890 non-null  object\n",
      " 6   Score              393890 non-null  int64 \n",
      " 7   Usefulness         393890 non-null  object\n",
      " 8   CleanedText        393884 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 27.0+ MB\n"
     ]
    }
   ],
   "source": [
    "proc_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_reviews = proc_reviews[proc_reviews['CleanedText'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Time</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Usefulness</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>useless</td>\n",
       "      <td>product arriv label jumbo salt peanut peanut a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>confect around centuri light pillowi citrus ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>look secret ingredi robitussin believ found go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>useless</td>\n",
       "      <td>great taffi great price wide assort yummi taff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId        Time SentimentPolarity  Class_Labels  \\\n",
       "0  B001E4KFG0  A3SGXH7AUHU8GW  2011-04-27          Positive             1   \n",
       "1  B00813GRG4  A1D87F6ZCVE5NK  2012-09-07          Negative             0   \n",
       "2  B000LQOCH0   ABXLMWJIXXAIN  2008-08-18          Positive             1   \n",
       "3  B000UA0QIQ  A395BORC6FGVXV  2011-06-13          Negative             0   \n",
       "4  B006K2ZZ7K  A1UQRSCLF8GW1T  2012-10-21          Positive             1   \n",
       "\n",
       "  Sentiment  Score Usefulness  \\\n",
       "0  positive      5       >75%   \n",
       "1  negative      1    useless   \n",
       "2  positive      4       >75%   \n",
       "3  negative      2       >75%   \n",
       "4  positive      5    useless   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  bought sever vital can dog food product found ...  \n",
       "1  product arriv label jumbo salt peanut peanut a...  \n",
       "2  confect around centuri light pillowi citrus ge...  \n",
       "3  look secret ingredi robitussin believ found go...  \n",
       "4  great taffi great price wide assort yummi taff...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - validation - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val_test, Y_train, Y_val_test = train_test_split(\n",
    "    proc_reviews[['CleanedText','Score']], proc_reviews['Score'], test_size=0.3, random_state=42, stratify=proc_reviews['Score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val, data_test, Y_val, Y_test = train_test_split(\n",
    "    data_val_test['CleanedText'], Y_val_test, test_size=0.333, random_state=42, stratify=data_val_test['Score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate lemmatized text from score on X_train (score was just kept for the second splitting)\n",
    "data_train = data_train['CleanedText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n",
      "(275718,) (275718,)\n",
      "(78816,) (78816,)\n",
      "(39350,) (39350,)\n"
     ]
    }
   ],
   "source": [
    "print(type(data_train),type(data_val),type(data_test))\n",
    "print(type(Y_train),type(Y_val),type(Y_test))\n",
    "\n",
    "print(data_train.shape,Y_train.shape)\n",
    "print(data_val.shape,Y_val.shape)\n",
    "print(data_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 250928, 4: 56086, 1: 36301, 3: 29768, 2: 20801})\n",
      "Counter({5: 175649, 4: 39260, 1: 25411, 3: 20837, 2: 14561})\n",
      "Counter({5: 50211, 4: 11223, 1: 7263, 3: 5957, 2: 4162})\n",
      "Counter({5: 25068, 4: 5603, 1: 3627, 3: 2974, 2: 2078})\n",
      "overall fractions = 63.71% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n",
      "train fractions = 63.71% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n",
      "val fractions = 63.71% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n",
      "test fractions = 63.71% 5 - 14.24% 4 - 7.56% 3 - 5.28% 2 - 9.22% 1\n"
     ]
    }
   ],
   "source": [
    "# Double check stratification is ok over the three splits\n",
    "\n",
    "all_counter = Counter(list(proc_reviews['Score']))\n",
    "train_counter = Counter(list(Y_train))\n",
    "val_counter = Counter(list(Y_val))\n",
    "test_counter = Counter(list(Y_test))\n",
    "\n",
    "num_all = len(list(proc_reviews['Score']))\n",
    "num_train = len(list(Y_train))\n",
    "num_val = len(list(Y_val))\n",
    "num_test = len(list(Y_test))\n",
    "\n",
    "print(all_counter)\n",
    "print(train_counter)\n",
    "print(val_counter)\n",
    "print(test_counter)\n",
    "\n",
    "print(f\"overall fractions = {all_counter[5]/num_all*100:.2f}% 5 - {all_counter[4]/num_all*100:.2f}% 4 - {all_counter[3]/num_all*100:.2f}% 3 - {all_counter[2]/num_all*100:.2f}% 2 - {all_counter[1]/num_all*100:.2f}% 1\")\n",
    "print(f\"train fractions = {train_counter[5]/num_train*100:.2f}% 5 - {train_counter[4]/num_train*100:.2f}% 4 - {train_counter[3]/num_train*100:.2f}% 3 - {train_counter[2]/num_train*100:.2f}% 2 - {train_counter[1]/num_train*100:.2f}% 1\")\n",
    "print(f\"val fractions = {val_counter[5]/num_val*100:.2f}% 5 - {val_counter[4]/num_val*100:.2f}% 4 - {val_counter[3]/num_val*100:.2f}% 3 - {val_counter[2]/num_val*100:.2f}% 2 - {val_counter[1]/num_val*100:.2f}% 1\")\n",
    "print(f\"test fractions = {test_counter[5]/num_test*100:.2f}% 5 - {test_counter[4]/num_test*100:.2f}% 4 - {test_counter[3]/num_test*100:.2f}% 3 - {test_counter[2]/num_test*100:.2f}% 2 - {test_counter[1]/num_test*100:.2f}% 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization strategy\n",
    "\n",
    "* TfidfVectorizer/CountVectorizer\n",
    "* FastVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf = utils.doc_vectorizer(data_train, data_val, data_test,\n",
    "\"tfidf\", {'min_df':1, 'ngram_range':(1,4), 'max_features':100000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_doc2vec, X_val_doc2vec, X_test_doc2vec \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_vectorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdoc2vec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvector_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwindow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mworkers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\j.martins\\Documents\\AI_HUB_Academy_training\\Capstone_project\\review-analysis-teamc\\code\\aml\\src\\prep\\utils.py:80\u001b[0m, in \u001b[0;36mdoc_vectorizer\u001b[1;34m(train_series, val_series, test_series, vectorizer_type, params_dic)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdoc_vectorizer\u001b[39m(train_series, val_series, test_series, vectorizer_type, params_dic):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorizer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc2vec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseries2doc2vec_vecs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m vectorizer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m series2tfidf_vecs(train_series, val_series, test_series, params_dic)\n",
      "File \u001b[1;32mc:\\Users\\j.martins\\Documents\\AI_HUB_Academy_training\\Capstone_project\\review-analysis-teamc\\code\\aml\\src\\prep\\utils.py:146\u001b[0m, in \u001b[0;36mseries2doc2vec_vecs\u001b[1;34m(train_series, val_series, test_series, params_dic)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m#doc2vec_model = Doc2Vec(vector_size=vector_size, window=window, min_count=min_count, workers=workers, epochs=epochs)\u001b[39;00m\n\u001b[0;32m    144\u001b[0m doc2vec_model \u001b[38;5;241m=\u001b[39m Doc2Vec(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_dic)\n\u001b[1;32m--> 146\u001b[0m \u001b[43mdoc2vec_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m doc2vec_model\u001b[38;5;241m.\u001b[39mtrain(docs_train,total_examples\u001b[38;5;241m=\u001b[39mdoc2vec_model\u001b[38;5;241m.\u001b[39mcorpus_count,epochs\u001b[38;5;241m=\u001b[39mdoc2vec_model\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m    149\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([doc2vec_model\u001b[38;5;241m.\u001b[39minfer_vector(docs_train[ind]\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(docs_train))])\n",
      "File \u001b[1;32mc:\\Users\\j.martins\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\doc2vec.py:882\u001b[0m, in \u001b[0;36mDoc2Vec.build_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_vocab\u001b[39m(\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;28mself\u001b[39m, corpus_iterable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, corpus_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, progress_per\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[0;32m    843\u001b[0m         keep_raw_vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, trim_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    844\u001b[0m     ):\n\u001b[0;32m    845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build vocabulary from a sequence of documents (can be a once-only generator stream).\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \n\u001b[0;32m    847\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    880\u001b[0m \n\u001b[0;32m    881\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m     total_words, corpus_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_vocab\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_per\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_per\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_rule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count \u001b[38;5;241m=\u001b[39m corpus_count\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words \u001b[38;5;241m=\u001b[39m total_words\n",
      "File \u001b[1;32mc:\\Users\\j.martins\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\doc2vec.py:1054\u001b[0m, in \u001b[0;36mDoc2Vec.scan_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1052\u001b[0m     corpus_iterable \u001b[38;5;241m=\u001b[39m TaggedLineDocument(corpus_file)\n\u001b[1;32m-> 1054\u001b[0m total_words, corpus_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scan_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_per\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollected \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m word types and \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m unique tags from a corpus of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m examples and \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m words\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_vocab), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdv), corpus_count, total_words,\n\u001b[0;32m   1059\u001b[0m )\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_words, corpus_count\n",
      "File \u001b[1;32mc:\\Users\\j.martins\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\models\\doc2vec.py:956\u001b[0m, in \u001b[0;36mDoc2Vec._scan_vocab\u001b[1;34m(self, corpus_iterable, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m document_no, document \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(corpus_iterable):\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m checked_string_types:\n\u001b[1;32m--> 956\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mdocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    957\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    958\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEach \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a list of words (usually unicode strings). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m here is instead plain \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    960\u001b[0m                 \u001b[38;5;28mtype\u001b[39m(document\u001b[38;5;241m.\u001b[39mwords),\n\u001b[0;32m    961\u001b[0m             )\n\u001b[0;32m    962\u001b[0m         checked_string_types \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "X_train_doc2vec, X_val_doc2vec, X_test_doc2vec = utils.doc_vectorizer(data_train, data_val, data_test, \"doc2vec\",\n",
    "                                                                      {'vector_size':2000, 'window':3, 'min_count':4, 'workers':2, 'epochs':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cntVec, X_val_cntVec, X_test_cntVec = utils.doc_vectorizer(data_train, data_val, data_test, \"countVec\",\n",
    "                                                                      {'min_df':1, 'ngram_range':(1,3)})\n",
    "\n",
    "#X_train_cntVec, X_val_cntVec, X_test_cntVec = utils.doc_vectorizer(data_train, data_val, data_test, \"countVec\",\n",
    "#                                                                      {'stop_words': None, 'min_df':1, 'max_df':1,\n",
    "#                                                                       'ngram_range':(1,3), 'max_features': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many features we are left with \n",
    "print(X_train_tfidf.shape)\n",
    "#print(X_train_doc2vec.shape)\n",
    "#print(X_train_cntVec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models analysis and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import models to try\n",
    "from sklearn.svm import LinearSVC # Support vector machine\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svm(random_state=42, tol=1e-3, class_weight='balanced'):\n",
    "\n",
    "    return LinearSVC(random_state=random_state, tol=tol, class_weight=class_weight)\n",
    "\n",
    "def train_svm(_model, X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "\n",
    "    _model.fit(X_train,Y_train)\n",
    "\n",
    "    Y_val_pred = _model.predict(X_val)\n",
    "\n",
    "    val_acc = accuracy_score(Y_val,Y_val_pred)\n",
    "\n",
    "    Y_test_pred = _model.predict(X_test)\n",
    "\n",
    "    test_acc = accuracy_score(Y_test,Y_test_pred)\n",
    "\n",
    "    return _model, val_acc, test_acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfidf = build_svm(random_state=42, tol=1e-4, class_weight='balanced')\n",
    "\n",
    "model_tfidf, val_acc, test_acc = train_svm(model_tfidf, X_train_tfidf, Y_train, X_val_tfidf, Y_val, X_test_tfidf, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cntVec = build_svm(random_state=42, tol=1e-3, class_weight='balanced')\n",
    "\n",
    "model_cntVec, val_acc_2, test_acc_2 = train_svm(model_cntVec, X_train_cntVec, Y_train, X_val_cntVec, Y_val, X_test_cntVec, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_2, test_acc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normalization of features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
